# -*- coding: utf-8 -*-
"""Word_Embedding_GPT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QEOXYr0J_J0X22wZhluIHUlBv89Rdtan
"""

from transformers import GPT2Tokenizer, GPT2Model
import torch

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2Model.from_pretrained("gpt2")

text = "The king is strong."

encoding = tokenizer(text, return_tensors="pt")

encoding

outputs = model(**encoding)

input_ids = encoding["input_ids"]
token_embeddings = model.wte(input_ids)  # wte = Word/token embeddings
position_embeddings = model.wpe(torch.arange(input_ids.size(1)).unsqueeze(0)) # wpe = Word/position embeddings

final_embeddings = token_embeddings + position_embeddings

print("Token Embeddings shape:", token_embeddings.shape)
print("Position Embeddings shape:", position_embeddings.shape)
print("Final Embeddings shape:", final_embeddings.shape)

final_embeddings

